{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOTA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhYk+XgSUm5F/Ev/gJtKKr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam-39/Position-and-Rotation-Invariant-Sign-Language-Recognition/blob/master/DOTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ7suZUqGJCo",
        "outputId": "38426665-4345-4dd9-b9b9-5944b906200c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZagxQw7SBLi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjsdL6mnSBDx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2T10CLZKP1i"
      },
      "source": [
        "## dota process\n",
        "\n",
        "import shapely.geometry as geometry\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "classnames = ['plane', 'baseball-diamond', 'bridge', 'ground-track-field', 'small-vehicle',\n",
        "              'large-vehicle', 'ship', 'tennis-court', 'basketball-court', 'storage-tank',\n",
        "              'soccer-ball-field', 'roundabout', 'harbor', 'swimming-pool', 'helicopter']\n",
        "\n",
        "\n",
        "########################################################\n",
        "#    parse the dota ground truth in the format:\n",
        "#    [x1, y1, x2, y2, x3, y3, x4, y4]\n",
        "########################################################\n",
        "def read_dota_gt(filename):\n",
        "\n",
        "    objects = parse_dota_box(filename)\n",
        "    for obj in objects:\n",
        "        obj['box'] = vertex_rect(obj['box'])\n",
        "        obj['box'] = list(map(int, obj['box']))\n",
        "    return objects\n",
        "\n",
        "\n",
        "########################################################\n",
        "# parse the dota ground truth in the format:\n",
        "# [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n",
        "########################################################\n",
        "def parse_dota_box(filename):\n",
        "    objects = []\n",
        "    fd = open(filename, 'r')\n",
        "    txt_lines = fd.readlines()\n",
        "    fd.close()\n",
        "    for idx in range(txt_lines.__len__()):\n",
        "        line = txt_lines[idx]\n",
        "        if line.strip('\\n') != '':\n",
        "            splitlines = line.strip().split(' ')\n",
        "            object_struct = {}\n",
        "            if len(splitlines) < 9:\n",
        "                continue\n",
        "            if len(splitlines) >= 9:\n",
        "                    object_struct['name'] = splitlines[8]\n",
        "            if len(splitlines) == 9:\n",
        "                object_struct['difficult'] = '0'\n",
        "            elif len(splitlines) >= 10:\n",
        "                object_struct['difficult'] = splitlines[9]\n",
        "            object_struct['box'] = [(float(splitlines[0]), float(splitlines[1])),\n",
        "                                    (float(splitlines[2]), float(splitlines[3])),\n",
        "                                    (float(splitlines[4]), float(splitlines[5])),\n",
        "                                    (float(splitlines[6]), float(splitlines[7]))]\n",
        "            gtbox = geometry.Polygon(object_struct['box'])\n",
        "            object_struct['area'] = gtbox.area\n",
        "            objects.append(object_struct)\n",
        "\n",
        "    return objects\n",
        "\n",
        "\n",
        "def vertex_rect(box):\n",
        "    outbox = [box[0][0], box[0][1], box[1][0], box[1][1], box[2][0], box[2][1], box[3][0], box[3][1]]\n",
        "    return outbox\n",
        "\n",
        "\n",
        "def calc_half_iou(box1, box2):\n",
        "    inter_box = box1.intersection(box2)\n",
        "    inter_area = inter_box.area\n",
        "    box1_area = box1.area\n",
        "    half_iou = inter_area / box1_area\n",
        "    return inter_box, half_iou\n",
        "\n",
        "\n",
        "def boxorig2sub(left, up, box):\n",
        "    boxInsub = np.zeros(len(box))\n",
        "    for i in range(int(len(box)/2)):\n",
        "        boxInsub[i * 2] = int(box[i * 2] - left)\n",
        "        boxInsub[i * 2 + 1] = int(box[i * 2 + 1] - up)\n",
        "    return boxInsub\n",
        "\n",
        "\n",
        "def box5_box4(box):\n",
        "    distances = [calc_line_length((box[i * 2], box[i * 2 + 1]), (box[(i + 1) * 2], box[(i + 1) * 2 + 1])) for i in range(int(len(box)/2 - 1))]\n",
        "    distances.append(calc_line_length((box[0], box[1]), (box[8], box[9])))\n",
        "    pos = np.array(distances).argsort()[0]\n",
        "    count = 0\n",
        "    outbox = []\n",
        "    while count < 5:\n",
        "        if count == pos:\n",
        "            outbox.append((box[count * 2] + box[(count * 2 + 2) % 10])/2)\n",
        "            outbox.append((box[(count * 2 + 1) % 10] + box[(count * 2 + 3) % 10])/2)\n",
        "            count = count + 1\n",
        "        elif count == (pos + 1) % 5:\n",
        "            count = count + 1\n",
        "            continue\n",
        "        else:\n",
        "            outbox.append(box[count * 2])\n",
        "            outbox.append(box[count * 2 + 1])\n",
        "            count = count + 1\n",
        "    return outbox\n",
        "\n",
        "\n",
        "def calc_line_length(point1, point2):\n",
        "    return math.sqrt(math.pow(point1[0] - point2[0], 2) + math.pow(point1[1] - point2[1], 2))\n",
        "\n",
        "\n",
        "def choose_best_point_order_fit_another(box1, box2):\n",
        "    x1 = box1[0]\n",
        "    y1 = box1[1]\n",
        "    x2 = box1[2]\n",
        "    y2 = box1[3]\n",
        "    x3 = box1[4]\n",
        "    y3 = box1[5]\n",
        "    x4 = box1[6]\n",
        "    y4 = box1[7]\n",
        "    combinate = [np.array([x1, y1, x2, y2, x3, y3, x4, y4]), np.array([x2, y2, x3, y3, x4, y4, x1, y1]),\n",
        "                 np.array([x3, y3, x4, y4, x1, y1, x2, y2]), np.array([x4, y4, x1, y1, x2, y2, x3, y3])]\n",
        "    dst_coordinate = np.array(box2)\n",
        "    distances = np.array([np.sum((coord - dst_coordinate)**2) for coord in combinate])\n",
        "    sorted = distances.argsort()\n",
        "    return combinate[sorted[0]]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdjrBt3iR9fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VnKBGzMSCQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OmFu19NGEZg"
      },
      "source": [
        "###   utils\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "####################################################\n",
        "##  //  import dota_process\n",
        "import shapely.geometry as geometry\n",
        "####################################################\n",
        "\n",
        "\n",
        "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
        "    if x1y1x2y2:\n",
        "        min_x = min(box1[0], box2[0])\n",
        "        max_x = max(box1[2], box2[2])\n",
        "        min_y = min(box1[1], box2[1])\n",
        "        max_y = max(box1[3], box2[3])\n",
        "        box1_w = box1[2] - box1[0]\n",
        "        box1_h = box1[3] - box1[1]\n",
        "        box2_w = box2[2] - box2[0]\n",
        "        box2_h = box2[3] - box2[1]\n",
        "    else:\n",
        "        min_x = min(box1[0]-box1[2]/2.0, box2[0]-box2[2]/2.0)\n",
        "        max_x = max(box1[0]+box1[2]/2.0, box2[0]+box2[2]/2.0)\n",
        "        min_y = min(box1[1]-box1[3]/2.0, box2[1]-box2[3]/2.0)\n",
        "        max_y = max(box1[1]+box1[3]/2.0, box2[1]+box2[3]/2.0)\n",
        "        box1_w = box1[2]\n",
        "        box1_h = box1[3]\n",
        "        box2_w = box2[2]\n",
        "        box2_h = box2[3]\n",
        "    union_w = max_x - min_x\n",
        "    union_h = max_y - min_y\n",
        "    inter_w = box1_w + box2_w - union_w\n",
        "    inter_h = box1_h + box2_h - union_h\n",
        "    if inter_w <= 0 or inter_h <= 0:\n",
        "        return 0.0\n",
        "    box1_area = box1_w * box1_h\n",
        "    box2_area = box2_w * box2_h\n",
        "    inter_area = inter_w * inter_h\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    return inter_area/union_area\n",
        "\n",
        "\n",
        "def bbox_ious(boxes1, boxes2, x1y1x2y2=True):\n",
        "    if x1y1x2y2:\n",
        "        min_x = torch.min(boxes1[0], boxes2[0])\n",
        "        max_x = torch.max(boxes1[2], boxes2[2])\n",
        "        min_y = torch.min(boxes1[1], boxes2[1])\n",
        "        max_y = torch.max(boxes1[3], boxes2[3])\n",
        "        box1_w = boxes1[2] - boxes1[0]\n",
        "        box1_h = boxes1[3] - boxes1[1]\n",
        "        box2_w = boxes2[2] - boxes2[0]\n",
        "        box2_h = boxes2[3] - boxes2[1]\n",
        "    else:\n",
        "        min_x = torch.min(boxes1[0]-boxes1[2]/2.0, boxes2[0]-boxes2[2]/2.0)\n",
        "        max_x = torch.max(boxes1[0]+boxes1[2]/2.0, boxes2[0]+boxes2[2]/2.0)\n",
        "        min_y = torch.min(boxes1[1]-boxes1[3]/2.0, boxes2[1]-boxes2[3]/2.0)\n",
        "        max_y = torch.max(boxes1[1]+boxes1[3]/2.0, boxes2[1]+boxes2[3]/2.0)\n",
        "        box1_w = boxes1[2]\n",
        "        box1_h = boxes1[3]\n",
        "        box2_w = boxes2[2]\n",
        "        box2_h = boxes2[3]\n",
        "    union_w = max_x - min_x\n",
        "    union_h = max_y - min_y\n",
        "    inter_w = box1_w + box2_w - union_w\n",
        "    inter_h = box1_h + box2_h - union_h\n",
        "    mask = ((inter_w <= 0) + (inter_h <= 0) > 0)\n",
        "    box1_area = box1_w * box1_h\n",
        "    box2_area = box2_w * box2_h\n",
        "    inter_area = inter_w * inter_h\n",
        "    inter_area[mask] = 0\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    return inter_area/union_area\n",
        "\n",
        "\n",
        "# def nms_cls(boxes, nms_thresh):\n",
        "#     if boxes.__len__() == 0:\n",
        "#         return boxes\n",
        "#     det_confs = torch.zeros(boxes.__len__())\n",
        "#     for i in range(boxes.__len__()):\n",
        "#         det_confs[i] = boxes[i][4]\n",
        "#     _,sortIds = torch.sort(det_confs, descending=True)\n",
        "#     out_boxes = []\n",
        "#     for i in range(len(boxes)):\n",
        "#         box_i = boxes[sortIds[i]]\n",
        "#         if box_i[4] > 0:\n",
        "#             out_boxes.append(box_i)\n",
        "#             for j in range(i+1, len(boxes)):\n",
        "#                 box_j = boxes[sortIds[j]]\n",
        "#                 if (box_j[4] != 0) & (box_i[6] == box_j[6]):\n",
        "#                     if bbox_iou(box_i, box_j, x1y1x2y2=False) > nms_thresh:\n",
        "#                         box_j[4] = 0\n",
        "#     return out_boxes\n",
        "\n",
        "def nms(boxes, nms_thresh):\n",
        "    if boxes.__len__() == 0:\n",
        "        return boxes\n",
        "\n",
        "    det_confs = torch.zeros(boxes.__len__())\n",
        "    for i in range(boxes.__len__()):\n",
        "        det_confs[i] = boxes[i][4]\n",
        "\n",
        "    _, sortIds = torch.sort(det_confs, descending=True)\n",
        "    out_boxes = []\n",
        "    for i in range(len(boxes)):\n",
        "        box_i = boxes[sortIds[i]]\n",
        "        if box_i[4] > 0:\n",
        "            out_boxes.append(box_i)\n",
        "            for j in range(i+1, len(boxes)):\n",
        "                box_j = boxes[sortIds[j]]\n",
        "                if box_j[4] != 0:\n",
        "                    if bbox_iou(box_i, box_j, x1y1x2y2=False) > nms_thresh:\n",
        "                        box_j[4] = 0\n",
        "    return out_boxes\n",
        "\n",
        "\n",
        "def convert2cpu(gpu_matrix):\n",
        "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
        "\n",
        "\n",
        "def plot_boxes(img, boxes, savename=None, class_names=None):\n",
        "\n",
        "    width = img.width\n",
        "    height = img.height\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    fnt = ImageFont.truetype('times.ttf', 20)\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        x1 = (box[0] - box[2] / 2.0) * width\n",
        "        y1 = (box[1] - box[3] / 2.0) * height\n",
        "        x2 = (box[0] + box[2] / 2.0) * width\n",
        "        y2 = (box[1] + box[3] / 2.0) * height\n",
        "\n",
        "        rgb = (255, 0, 0)\n",
        "        if len(box) >= 7 and class_names:\n",
        "            cls_conf = box[5]\n",
        "            cls_id = box[6]\n",
        "            print('%s: %f' % (class_names[cls_id], cls_conf))\n",
        "            classes = len(class_names)\n",
        "            offset = cls_id * 123457 % classes\n",
        "            red = get_color(2, offset, classes)\n",
        "            green = get_color(1, offset, classes)\n",
        "            blue = get_color(0, offset, classes)\n",
        "            rgb = (red, green, blue)\n",
        "            draw.text((x1, y1), class_names[cls_id], fill=rgb, font=fnt)\n",
        "        draw_rect(draw, [x1, y1, x2, y2], rgb, 4)\n",
        "    if savename:\n",
        "        print(\"save plot results to %s\" % savename)\n",
        "        img.save(savename)\n",
        "    return img\n",
        "\n",
        "\n",
        "def draw_rect(drawcontext, xy, color=None, width=1):\n",
        "    offset = 1\n",
        "    for i in range(0, width):\n",
        "        drawcontext.rectangle(xy, outline=color)\n",
        "        xy[0] = xy[0] - offset\n",
        "        xy[1] = xy[1] + offset\n",
        "        xy[2] = xy[2] + offset\n",
        "        xy[3] = xy[3] - offset\n",
        "\n",
        "\n",
        "def get_color(c, x, max_val):\n",
        "    colors = torch.FloatTensor([[1, 0, 1], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0]]);\n",
        "    ratio = float(x) / max_val * 5\n",
        "    i = int(math.floor(ratio))\n",
        "    j = int(math.ceil(ratio))\n",
        "    ratio = ratio - i\n",
        "    r = (1 - ratio) * colors[i][c] + ratio * colors[j][c]\n",
        "    return int(r * 255)\n",
        "\n",
        "\n",
        "def truths_length(truths):\n",
        "    for i in range(800):\n",
        "        if truths[i][1] == 0:\n",
        "            return i\n",
        "    return 800\n",
        "\n",
        "\n",
        "####################################################\n",
        "def read_truths_args(lab_path, min_box_scale, shape):\n",
        "    new_truths = []\n",
        "    objects = dota_process.read_dota_gt(lab_path)\n",
        "    for obj in objects:\n",
        "        gtbox = geometry.Polygon([(obj['box'][0], obj['box'][1]),\n",
        "                                   (obj['box'][2], obj['box'][3]),\n",
        "                                   (obj['box'][4], obj['box'][5]),\n",
        "                                   (obj['box'][6], obj['box'][7])])\n",
        "        out_box = gtbox.exterior.bounds\n",
        "        x = abs(out_box[2] + out_box[0]) / (2. * shape[0])\n",
        "        y = abs(out_box[1] + out_box[3]) / (2. * shape[1])\n",
        "        w = abs(out_box[2] - out_box[0]) / shape[0]\n",
        "        h = abs(out_box[3] - out_box[1]) / shape[1]\n",
        "        if (max(w, h) < min_box_scale) or ((w*h) < (min_box_scale*min_box_scale)):\n",
        "            continue\n",
        "        c = dota_process.classnames.index(obj['name'])\n",
        "        new_truths.append([c, x, y, w, h])\n",
        "    return np.array(new_truths)\n",
        "####################################################\n",
        "\n",
        "\n",
        "def load_class_names(names_file):\n",
        "    class_names = []\n",
        "    fp = open(names_file, 'r')\n",
        "    lines = fp.readlines()\n",
        "    fp.close()\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip('\\n')\n",
        "        class_names.append(line)\n",
        "    return class_names\n",
        "\n",
        "\n",
        "def read_data_cfg(datacfg):\n",
        "    options = dict()\n",
        "    options['gpus'] = '0'\n",
        "    fp = open(datacfg, 'r')\n",
        "    lines = fp.readlines()\n",
        "    fp.close()\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip('\\n')\n",
        "        if line == '':\n",
        "            continue\n",
        "        key, value = line.split('=')\n",
        "        key = key.strip()\n",
        "        value = value.strip()\n",
        "        options[key] = value\n",
        "    return options\n",
        "\n",
        "\n",
        "def file_lines(file_path):\n",
        "    fd = open(file_path, 'r')\n",
        "    file_lines = fd.readlines()\n",
        "    fd.close()\n",
        "    lines = file_lines.__len__()\n",
        "    for idx in range(lines):\n",
        "        if file_lines[lines-idx-1].strip('\\n') == '':\n",
        "            lines = lines - 1\n",
        "        else:\n",
        "            break\n",
        "    return lines\n",
        "\n",
        "\n",
        "def logging(message):\n",
        "    print('%s %s' % (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), message))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE1ZJCGrSZO4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVftVVFSZLS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHob2pTBGI53"
      },
      "source": [
        "########################  config\n",
        "\n",
        "import torch\n",
        "##  //  from utils import convert2cpu\n",
        "\n",
        "\n",
        "def parse_cfg(cfgfile):\n",
        "    blocks = []\n",
        "    fp = open(cfgfile, 'r')\n",
        "    block = None\n",
        "    line = fp.readline()\n",
        "    while line != '':\n",
        "        line = line.rstrip()\n",
        "        if line == '' or line[0] == '#':\n",
        "            line = fp.readline()\n",
        "            continue        \n",
        "        elif line[0] == '[':\n",
        "            if block:\n",
        "                blocks.append(block)\n",
        "            block = dict()\n",
        "            block['type'] = line.lstrip('[').rstrip(']')\n",
        "            if block['type'] == 'convolutional':\n",
        "                block['batch_normalize'] = 0\n",
        "        else:\n",
        "            key, value = line.split('=')\n",
        "            key = key.strip()\n",
        "            if key == 'type':\n",
        "                key = '_type'\n",
        "            value = value.strip()\n",
        "            block[key] = value\n",
        "        line = fp.readline()\n",
        "\n",
        "    if block:\n",
        "        blocks.append(block)\n",
        "    fp.close()\n",
        "    return blocks\n",
        "\n",
        "\n",
        "def load_conv(buf, start, conv_model):\n",
        "    if conv_model.bias is not None:\n",
        "        num_b = conv_model.bias.numel()\n",
        "        conv_model.bias.data.copy_(torch.from_numpy(buf[start:start + num_b]))\n",
        "        start = start + num_b\n",
        "    num_w = conv_model.weight.numel()\n",
        "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]).view(conv_model.weight.shape)); start = start + num_w\n",
        "    return start\n",
        "\n",
        "\n",
        "def load_deform_conv(buf, start, conv_model):\n",
        "    num_w = conv_model.weight.numel()\n",
        "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]).view(conv_model.weight.shape))\n",
        "    start = start + num_w\n",
        "\n",
        "    num_w = conv_model.layer_1.weight.numel()\n",
        "    conv_model.layer_1.weight.data.copy_(torch.from_numpy(buf[start:start + num_w]).view(conv_model.layer_1.weight.shape))\n",
        "    start = start + num_w\n",
        "    return start\n",
        "\n",
        "\n",
        "def save_conv(fp, conv_model):\n",
        "    if conv_model.weight.is_cuda:\n",
        "        if conv_model.bias is not None:\n",
        "            convert2cpu(conv_model.bias.data).numpy().tofile(fp)\n",
        "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
        "    else:\n",
        "        if conv_model.bias is not None:\n",
        "            conv_model.bias.data.numpy().tofile(fp)\n",
        "        conv_model.weight.data.numpy().tofile(fp)\n",
        "\n",
        "\n",
        "def save_deform_conv(fp, conv_model):\n",
        "    if conv_model.weight.is_cuda:\n",
        "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
        "        convert2cpu(conv_model.layer_1.weight.data).numpy().tofile(fp)\n",
        "    else:\n",
        "        conv_model.weight.data.numpy().tofile(fp)\n",
        "        conv_model.layer_1.weight.data.numpy().tofile(fp)\n",
        "\n",
        "\n",
        "def load_conv_bn(buf, start, conv_model, bn_model):\n",
        "    num_w = conv_model.weight.numel()\n",
        "\n",
        "    num_b = bn_model.bias.numel()\n",
        "    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n",
        "    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start+num_b]));  start = start + num_b\n",
        "    bn_model.running_var.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]).view(conv_model.weight.shape)); start = start + num_w\n",
        "    if conv_model.bias is not None:\n",
        "        num_w_b = conv_model.bias.numel()\n",
        "        conv_model.bias.data.copy_(torch.from_numpy(buf[start:start + num_w_b]).view(conv_model.bias.shape)); start = start + num_w_b\n",
        "    return start\n",
        "\n",
        "\n",
        "def load_bn(buf, start, bn_model):\n",
        "    num_b = bn_model.bias.numel()\n",
        "    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n",
        "    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start+num_b]));  start = start + num_b\n",
        "    bn_model.running_var.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
        "    return start\n",
        "\n",
        "\n",
        "def save_bn(fp, bn_model):\n",
        "    if bn_model.bias.is_cuda:\n",
        "        convert2cpu(bn_model.bias.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.weight.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_mean).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_var).numpy().tofile(fp)\n",
        "    else:\n",
        "        bn_model.bias.data.numpy().tofile(fp)\n",
        "        bn_model.weight.data.numpy().tofile(fp)\n",
        "        bn_model.running_mean.numpy().tofile(fp)\n",
        "        bn_model.running_var.numpy().tofile(fp)\n",
        "\n",
        "\n",
        "def save_conv_bn(fp, conv_model, bn_model):\n",
        "    if bn_model.bias.is_cuda:\n",
        "        convert2cpu(bn_model.bias.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.weight.data).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_mean).numpy().tofile(fp)\n",
        "        convert2cpu(bn_model.running_var).numpy().tofile(fp)\n",
        "        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n",
        "        if conv_model.bias is not None:\n",
        "            convert2cpu(conv_model.bias.data).numpy().tofile(fp)\n",
        "    else:\n",
        "        bn_model.bias.data.numpy().tofile(fp)\n",
        "        bn_model.weight.data.numpy().tofile(fp)\n",
        "        bn_model.running_mean.numpy().tofile(fp)\n",
        "        bn_model.running_var.numpy().tofile(fp)\n",
        "        conv_model.weight.data.numpy().tofile(fp)\n",
        "        if conv_model.bias is not None:\n",
        "            conv_model.bias.data.numpy().tofile(fp)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Gvp292KTQ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXUGiBssKTN3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SLmCaDfLNas"
      },
      "source": [
        "##  iorn\n",
        "\n",
        "import torch\n",
        "from torch.nn.modules.module import Module\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd.variable import Variable\n",
        "\n",
        "class ORBatchNorm2d(Module):\n",
        "\n",
        "    def __init__(self, num_features, nOrientation, eps=1e-5, momentum=0.1, affine=True):\n",
        "        super(ORBatchNorm2d, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.nOrientation = nOrientation\n",
        "        self.affine = affine\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        if self.affine:\n",
        "            self.weight = Parameter(torch.Tensor(num_features))\n",
        "            self.bias = Parameter(torch.Tensor(num_features))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "            self.register_parameter('bias', None)\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "        self.register_buffer('running_var', torch.ones(num_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.running_mean.zero_()\n",
        "        self.running_var.fill_(1)\n",
        "        if self.affine:\n",
        "            self.weight.data.uniform_()\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size, channels, h, w = input.size()\n",
        "\n",
        "        input_reshaped = input.view(batch_size, channels//self.nOrientation, h*self.nOrientation, w)\n",
        "\n",
        "        result = F.batch_norm(\n",
        "            input_reshaped, self.running_mean, self.running_var, self.weight, self.bias,\n",
        "            self.training, self.momentum, self.eps)\n",
        "\n",
        "        return result.view(batch_size, channels, h, w)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return ('{name}({num_features}, eps={eps}, momentum={momentum},'\n",
        "                ' affine={affine})'\n",
        "                .format(name=self.__class__.__name__, **self.__dict__))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQnXJpLuKTLg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl1Eu2qGKTI3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eI6zS5ZKPta"
      },
      "source": [
        "##  region_loss\n",
        "\n",
        "##  //  from utils import *\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def build_targets(pred_boxes, target, anchors, num_anchors, nH, nW, noobject_scale, object_scale, sil_thresh, seen):\n",
        "    nB = target.size(0)\n",
        "    nA = num_anchors\n",
        "    anchor_step = len(anchors)//num_anchors\n",
        "    conf_mask = torch.ones(nB, nA, nH, nW) * noobject_scale\n",
        "    coord_mask = torch.zeros(nB, nA, nH, nW)\n",
        "    cls_mask = torch.zeros(nB, nA, nH, nW)\n",
        "    tx = torch.zeros(nB, nA, nH, nW)\n",
        "    ty = torch.zeros(nB, nA, nH, nW)\n",
        "    tw = torch.zeros(nB, nA, nH, nW)\n",
        "    th = torch.zeros(nB, nA, nH, nW)\n",
        "    tconf = torch.zeros(nB, nA, nH, nW)\n",
        "    tcls = torch.zeros(nB, nA, nH, nW)\n",
        "\n",
        "    nAnchors = nA*nH*nW\n",
        "    nPixels  = nH*nW\n",
        "    for b in range(nB):\n",
        "        cur_pred_boxes = pred_boxes[b*nAnchors:(b+1)*nAnchors].t()\n",
        "        cur_ious = torch.zeros(nAnchors)\n",
        "        for t in range(800):\n",
        "            if target[b][t*5+1] == 0:\n",
        "                break\n",
        "            gx = target[b][t*5+1]*nW\n",
        "            gy = target[b][t*5+2]*nH\n",
        "            gw = target[b][t*5+3]*nW\n",
        "            gh = target[b][t*5+4]*nH\n",
        "            cur_gt_boxes = torch.FloatTensor([gx, gy, gw, gh]).repeat(nAnchors, 1).t()\n",
        "            cur_ious = torch.max(cur_ious, bbox_ious(cur_pred_boxes, cur_gt_boxes, x1y1x2y2=False))\n",
        "        conf_mask[b][cur_ious > sil_thresh] = 0\n",
        "    if seen < 12800:\n",
        "        if anchor_step == 4:\n",
        "            tx = torch.FloatTensor(anchors).view(nA, anchor_step).index_select(1, torch.LongTensor([2])).view(1, nA, 1, 1).repeat(nB, 1, nH,nW)\n",
        "            ty = torch.FloatTensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([2])).view(1, nA, 1, 1).repeat(nB, 1, nH, nW)\n",
        "        else:\n",
        "            tx.fill_(0.5)\n",
        "            ty.fill_(0.5)\n",
        "        tw.zero_()\n",
        "        th.zero_()\n",
        "        coord_mask.fill_(1)\n",
        "\n",
        "    nGT = 0\n",
        "    nCorrect = 0\n",
        "    for b in range(nB):\n",
        "        for t in range(800):\n",
        "            if target[b][t*5+1] == 0:\n",
        "                break\n",
        "            nGT = nGT + 1\n",
        "            best_iou = 0.0\n",
        "            best_n = -1\n",
        "            min_dist = 10000\n",
        "            gx = target[b][t*5+1] * nW\n",
        "            gy = target[b][t*5+2] * nH\n",
        "            gi = int(gx)\n",
        "            gj = int(gy)\n",
        "            gw = target[b][t*5+3]*nW\n",
        "            gh = target[b][t*5+4]*nH\n",
        "            gt_box = [0, 0, gw, gh]\n",
        "            for n in range(nA):\n",
        "                aw = anchors[anchor_step*n]\n",
        "                ah = anchors[anchor_step*n+1]\n",
        "                anchor_box = [0, 0, aw, ah]\n",
        "                iou = bbox_iou(anchor_box, gt_box, x1y1x2y2=False)\n",
        "                if anchor_step == 4:\n",
        "                    ax = anchors[anchor_step*n+2]\n",
        "                    ay = anchors[anchor_step*n+3]\n",
        "                    dist = pow(((gi+ax) - gx), 2) + pow(((gj+ay) - gy), 2)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_n = n\n",
        "                elif anchor_step == 4 and iou == best_iou and dist < min_dist:\n",
        "                    best_iou = iou\n",
        "                    best_n = n\n",
        "                    min_dist = dist\n",
        "\n",
        "            gt_box = [gx, gy, gw, gh]\n",
        "            pred_box = pred_boxes[b*nAnchors+best_n*nPixels+gj*nW+gi]\n",
        "\n",
        "            coord_mask[b][best_n][gj][gi] = 1\n",
        "            cls_mask[b][best_n][gj][gi] = 1\n",
        "            conf_mask[b][best_n][gj][gi] = object_scale\n",
        "            tx[b][best_n][gj][gi] = target[b][t*5+1] * nW - gi\n",
        "            ty[b][best_n][gj][gi] = target[b][t*5+2] * nH - gj\n",
        "            tw[b][best_n][gj][gi] = math.log(gw/anchors[anchor_step*best_n])\n",
        "            th[b][best_n][gj][gi] = math.log(gh/anchors[anchor_step*best_n+1])\n",
        "            iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False)\n",
        "            tconf[b][best_n][gj][gi] = iou\n",
        "            tcls[b][best_n][gj][gi] = target[b][t*5]\n",
        "            if iou > 0.5:\n",
        "                nCorrect = nCorrect + 1\n",
        "\n",
        "    return nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf, tcls\n",
        "\n",
        "\n",
        "class RegionLoss(nn.Module):\n",
        "    def __init__(self, num_classes=0, anchors=[], num_anchors=1):\n",
        "        super(RegionLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = num_anchors\n",
        "        self.anchor_step = len(anchors)/num_anchors\n",
        "        self.coord_scale = 1\n",
        "        self.noobject_scale = 1\n",
        "        self.object_scale = 5\n",
        "        self.class_scale = 1\n",
        "        self.thresh = 0.6\n",
        "        self.seen = 0\n",
        "        self.iter_cnt = 0\n",
        "\n",
        "    def forward(self, output, target, batch_idx):\n",
        "        nB = output.data.size(0)\n",
        "        nA = self.num_anchors\n",
        "        nC = self.num_classes\n",
        "        nH = output.data.size(2)\n",
        "        nW = output.data.size(3)\n",
        "\n",
        "        output = output.view(nB, nA, (5+nC), nH, nW)\n",
        "        x = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([0]))).view(nB, nA, nH, nW))\n",
        "        y = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([1]))).view(nB, nA, nH, nW))\n",
        "        w = output.index_select(2, Variable(torch.cuda.LongTensor([2]))).view(nB, nA, nH, nW)\n",
        "        h = output.index_select(2, Variable(torch.cuda.LongTensor([3]))).view(nB, nA, nH, nW)\n",
        "        conf = F.sigmoid(output.index_select(2, Variable(torch.cuda.LongTensor([4]))).view(nB, nA, nH, nW))\n",
        "        cls = output.index_select(2, Variable(torch.linspace(5,5+nC-1,nC).long().cuda()))\n",
        "        cls = cls.view(nB*nA, nC, nH*nW).transpose(1,2).contiguous().view(nB*nA*nH*nW, nC)\n",
        "\n",
        "        pred_boxes = torch.cuda.FloatTensor(4, nB, nA, nH, nW)\n",
        "        grid_x = torch.linspace(0, nW-1, nW).repeat(nH,1).repeat(nB*nA, 1, 1).view(nB, nA, nH, nW).cuda()\n",
        "        grid_y = torch.linspace(0, nH-1, nH).repeat(nW,1).t().repeat(nB*nA, 1, 1).view(nB, nA, nH, nW).cuda()\n",
        "        anchor_w = torch.Tensor(self.anchors).view(nA, self.anchor_step).index_select(1, torch.LongTensor([0])).cuda()\n",
        "        anchor_h = torch.Tensor(self.anchors).view(nA, self.anchor_step).index_select(1, torch.LongTensor([1])).cuda()\n",
        "        anchor_w = anchor_w.repeat(nB, 1).repeat(1, 1, nH*nW).view(nB, nA, nH, nW) #note\n",
        "        anchor_h = anchor_h.repeat(nB, 1).repeat(1, 1, nH*nW).view(nB, nA, nH, nW) #note\n",
        "        pred_boxes[0] = x.data + grid_x\n",
        "        pred_boxes[1] = y.data + grid_y\n",
        "        pred_boxes[2] = torch.exp(w.data) * anchor_w\n",
        "        pred_boxes[3] = torch.exp(h.data) * anchor_h\n",
        "        pred_boxes = convert2cpu(pred_boxes.view(4, -1).transpose(0, 1).contiguous().view(-1, 4))\n",
        "\n",
        "        nGT, nCorrect, coord_mask, conf_mask, cls_mask, tx, ty, tw, th, tconf,tcls = build_targets(pred_boxes,\n",
        "                                                        target.data, self.anchors, nA, nH, nW, self.noobject_scale,\n",
        "                                                        self.object_scale, self.thresh, self.seen)\n",
        "        cls_mask = (cls_mask == 1)\n",
        "        nProposals = int((conf.data > 0.25).sum())\n",
        "        tx    = Variable(tx.cuda())\n",
        "        ty    = Variable(ty.cuda())\n",
        "        tw    = Variable(tw.cuda())\n",
        "        th    = Variable(th.cuda())\n",
        "        tconf = Variable(tconf.cuda())\n",
        "        tcls  = Variable(tcls[cls_mask].view(-1).long().cuda())\n",
        "\n",
        "        coord_mask = Variable(coord_mask.cuda())\n",
        "        conf_mask  = Variable(conf_mask.cuda().sqrt())\n",
        "        cls_mask   = Variable(cls_mask.view(-1, 1).repeat(1, nC).cuda())\n",
        "        cls        = cls[cls_mask].view(-1, nC)\n",
        "\n",
        "        loss_x = self.coord_scale * nn.MSELoss(size_average=False)(x*coord_mask, tx*coord_mask)/2.0\n",
        "        loss_y = self.coord_scale * nn.MSELoss(size_average=False)(y*coord_mask, ty*coord_mask)/2.0\n",
        "        loss_w = self.coord_scale * nn.MSELoss(size_average=False)(w*coord_mask, tw*coord_mask)/2.0\n",
        "        loss_h = self.coord_scale * nn.MSELoss(size_average=False)(h*coord_mask, th*coord_mask)/2.0\n",
        "        loss_conf = nn.MSELoss(size_average=False)(conf*conf_mask, tconf*conf_mask)/2.0\n",
        "        if tcls.shape[0] != 0:\n",
        "            loss_cls = self.class_scale * nn.CrossEntropyLoss(size_average=False)(cls, tcls)\n",
        "        else:\n",
        "            loss_cls = Variable(torch.zeros(1))\n",
        "        loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls\n",
        "\n",
        "        print('%d: nGT %d, recall %d, proposals %d, loss: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f' %\n",
        "              (self.seen, nGT, nCorrect, nProposals, loss_x.data[0], loss_y.data[0], loss_w.data[0], loss_h.data[0],\n",
        "               loss_conf.data[0], loss_cls.data[0], loss.data[0]))\n",
        "\n",
        "        self.iter_cnt = self.iter_cnt + 1\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFTiAxvKTCG8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89IRABStTCBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQvncT6WJuSo"
      },
      "source": [
        "##   model_network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "##  //  from region_loss import RegionLoss\n",
        "##  //  from config import *\n",
        "##  //  from iorn.modules import ORConv2d\n",
        "##  //  from iorn_bn import ORBatchNorm2d\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors,\n",
        "                     x_start=0, y_start=0, imgwidth=0, imgheight=0, validation=False):\n",
        "    anchor_step = len(anchors) // num_anchors\n",
        "    if output.dim() == 3:\n",
        "        output = output.unsqueeze(0)\n",
        "    batch = output.size(0)\n",
        "    assert (output.size(1) == (5 + num_classes) * num_anchors)\n",
        "    h = output.size(2)\n",
        "    w = output.size(3)\n",
        "    all_boxes = []\n",
        "    output = output.view(batch * num_anchors, 5 + num_classes, h * w).\\\n",
        "        transpose(0, 1).contiguous().view(5 + num_classes, batch * num_anchors * h * w)\n",
        "\n",
        "    grid_x = torch.linspace(0, w - 1, w).repeat(h, 1).repeat(batch * num_anchors, 1, 1).view(\n",
        "        batch * num_anchors * h * w).cuda()\n",
        "    grid_y = torch.linspace(0, h - 1, h).repeat(w, 1).t().repeat(batch * num_anchors, 1, 1).view(\n",
        "        batch * num_anchors * h * w).cuda()\n",
        "    xs = torch.sigmoid(output[0]) + grid_x\n",
        "    ys = torch.sigmoid(output[1]) + grid_y\n",
        "\n",
        "    anchor_w = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([0]))\n",
        "    anchor_h = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([1]))\n",
        "    anchor_w = anchor_w.repeat(batch, 1).repeat(1, 1, h * w).view(batch * num_anchors * h * w).cuda()\n",
        "    anchor_h = anchor_h.repeat(batch, 1).repeat(1, 1, h * w).view(batch * num_anchors * h * w).cuda()\n",
        "    ws = torch.exp(output[2]) * anchor_w\n",
        "    hs = torch.exp(output[3]) * anchor_h\n",
        "\n",
        "    det_confs = torch.sigmoid(output[4])\n",
        "    cls_confs = torch.nn.Softmax(dim=1)((Variable(output[5:5 + num_classes].transpose(0, 1)))).data\n",
        "    cls_max_confs, cls_max_ids = torch.max(cls_confs, 1)\n",
        "    cls_max_confs = cls_max_confs.view(-1)\n",
        "    cls_max_ids = cls_max_ids.view(-1)\n",
        "\n",
        "    sz_hw = h * w\n",
        "    sz_hwa = sz_hw * num_anchors\n",
        "    box_idx = torch.nonzero(det_confs > conf_thresh)\n",
        "\n",
        "    if not validation:\n",
        "        for b_idx in range(batch):\n",
        "            boxes = []\n",
        "            for ind in box_idx:\n",
        "                if (ind >= b_idx * sz_hwa) and (ind < sz_hwa * (b_idx + 1)):\n",
        "                    det_conf = det_confs[ind][0]\n",
        "                    bcx = xs[ind][0]\n",
        "                    bcy = ys[ind][0]\n",
        "                    bw = ws[ind][0]\n",
        "                    bh = hs[ind][0]\n",
        "                    cls_max_conf = cls_max_confs[ind][0]\n",
        "                    cls_max_id = cls_max_ids[ind][0]\n",
        "                    box = [bcx / w, bcy / h, bw / w, bh / h, det_conf, cls_max_conf, cls_max_id]\n",
        "                    boxes.append(box)\n",
        "            all_boxes.append(boxes)\n",
        "    else:\n",
        "        for b_idx in range(batch):\n",
        "            boxes = []\n",
        "            for ind in box_idx:\n",
        "                if (ind >= b_idx * sz_hwa) and (ind < sz_hwa * (b_idx + 1)):\n",
        "                    det_conf = det_confs[ind][0]\n",
        "                    bcx = xs[ind][0]\n",
        "                    bcy = ys[ind][0]\n",
        "                    bw = ws[ind][0]\n",
        "                    bh = hs[ind][0]\n",
        "                    cls_max_conf = cls_max_confs[ind][0]\n",
        "                    cls_max_id = cls_max_ids[ind][0]\n",
        "                    box = [(x_start + (bcx / w) * 1024.0) / imgwidth, (y_start + (bcy / h) * 1024.0) / imgheight,\n",
        "                           ((bw / w) * 1024.0) / imgwidth, ((bh / h) * 1024.0) / imgheight, det_conf, cls_max_conf,\n",
        "                           cls_max_id]\n",
        "                    # box = [bcx / w, bcy / h, bw / w, bh / h, det_conf, cls_max_conf, cls_max_id]\n",
        "                    boxes.append(box)\n",
        "            all_boxes.append(boxes)\n",
        "    return all_boxes\n",
        "\n",
        "\n",
        "class MaxPoolStride(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MaxPoolStride, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.pad(x, (0, 1, 0, 1), mode='replicate'), 2, stride=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EmpotyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmpotyModule, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "class deformDarknet(nn.Module):\n",
        "    def __init__(self, cfgfile):\n",
        "        super(deformDarknet, self).__init__()\n",
        "        self.blocks = parse_cfg(cfgfile)\n",
        "        self.models = self.create_network(self.blocks)\n",
        "        self.loss = self.models[len(self.models) - 1]\n",
        "\n",
        "        self.width = int(self.blocks[0]['width'])\n",
        "        self.height = int(self.blocks[0]['height'])\n",
        "\n",
        "        if self.blocks[(len(self.blocks) - 1)]['type'] == 'region':\n",
        "            self.anchors = self.loss.anchors\n",
        "            self.num_anchors = self.loss.num_anchors\n",
        "            self.anchor_step = self.loss.anchor_step\n",
        "            self.num_classes = self.loss.num_classes\n",
        "\n",
        "        self.header = torch.IntTensor([0, 0, 0, 0])\n",
        "        self.seen = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        ind = -2\n",
        "        self.loss = None\n",
        "        outputs = dict()\n",
        "        for block in self.blocks:\n",
        "            ind = ind + 1\n",
        "            if block['type'] == 'net':\n",
        "                continue\n",
        "            elif block['type'] == 'iorn_convolutional' or block['type'] == 'convolutional' or\\\n",
        "                    block['type'] == 'maxpool':\n",
        "                x = self.models[ind](x)\n",
        "                outputs[ind] = x\n",
        "            elif block['type'] == 'trans_conv':\n",
        "                x = self.models[ind](x)\n",
        "                outputs[ind] = x\n",
        "            elif block['type'] == 'route':\n",
        "                layers = block['layers'].split(',')\n",
        "                layers = [int(i) if int(i) > 0 else int(i) + ind for i in layers]\n",
        "                if len(layers) == 1:\n",
        "                    x = outputs[layers[0]]\n",
        "                    outputs[ind] = x\n",
        "                elif len(layers) == 2:\n",
        "                    x1 = outputs[layers[0]]\n",
        "                    x2 = outputs[layers[1]]\n",
        "                    x = torch.cat((x1, x2), 1)\n",
        "                    outputs[ind] = x\n",
        "                elif len(layers) == 3:\n",
        "                    x1 = outputs[layers[0]]\n",
        "                    x2 = outputs[layers[1]]\n",
        "                    x3 = outputs[layers[2]]\n",
        "                    x = torch.cat((x1, x2, x3), 1)\n",
        "                    outputs[ind] = x\n",
        "            elif block['type'] == 'region':\n",
        "                continue\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "        return x\n",
        "\n",
        "    def create_network(self, blocks):\n",
        "        models = nn.ModuleList()\n",
        "        prev_filters = 3\n",
        "        out_filters = []\n",
        "        conv_id = 0\n",
        "        for block in blocks:\n",
        "            if block['type'] == 'net':\n",
        "                prev_filters = int(block['channels'])\n",
        "                continue\n",
        "            elif block['type'] == 'iorn_convolutional':\n",
        "                conv_id = conv_id + 1\n",
        "                iorn_id = 1\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                filters = int(block['filters'])\n",
        "                activation = block['activation']\n",
        "                pad = int(block['pad'])\n",
        "                dilate = int(block['dilate'])\n",
        "                stride = int(block['stride'])\n",
        "                nOrientation = int(block['nOrientation'])\n",
        "                model = nn.Sequential()\n",
        "                if batch_normalize:\n",
        "                    if iorn_id == 1:\n",
        "                        model.add_module('conv{0}'.format(conv_id),\n",
        "                                     ORConv2d(prev_filters, filters // nOrientation,\n",
        "                                              arf_config=(1, nOrientation), kernel_size=3,\n",
        "                                              padding=pad, stride=stride, dilation=dilate))\n",
        "                    else:\n",
        "                        model.add_module('conv{0}'.format(conv_id),\n",
        "                                         ORConv2d(prev_filters // nOrientation, filters // nOrientation,\n",
        "                                                  arf_config=nOrientation, kernel_size=3,\n",
        "                                                  padding=pad, stride=stride, dilation=dilate))\n",
        "                    model.add_module('bn{0}'.format(conv_id), ORBatchNorm2d(filters // nOrientation, nOrientation))\n",
        "                else:\n",
        "                    if iorn_id == 1:\n",
        "                        model.add_module('conv{0}'.format(conv_id),\n",
        "                                         ORConv2d(prev_filters, filters / nOrientation, arf_config=nOrientation,\n",
        "                                                  kernel_size=3, padding=1))\n",
        "                    else:\n",
        "                        model.add_module('conv{0}'.format(conv_id),\n",
        "                                         ORConv2d(prev_filters // nOrientation, filters // nOrientation,\n",
        "                                                  arf_config=nOrientation, kernel_size=3, padding=1))\n",
        "                if activation == 'leaky':\n",
        "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
        "                elif activation == 'relu':\n",
        "                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\n",
        "                prev_filters = filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'convolutional':\n",
        "                conv_id = conv_id + 1\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                filters = int(block['filters'])\n",
        "                kernel_size = int(block['size'])\n",
        "                stride = int(block['stride'])\n",
        "                is_pad = int(block['pad'])\n",
        "                pad = (kernel_size - 1) // 2 if is_pad else 0\n",
        "                activation = block['activation']\n",
        "                model = nn.Sequential()\n",
        "                if batch_normalize:\n",
        "                    model.add_module('conv{0}'.format(conv_id),\n",
        "                                     nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=False))\n",
        "                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\n",
        "                else:\n",
        "                    model.add_module('conv{0}'.format(conv_id),\n",
        "                                     nn.Conv2d(prev_filters, filters, kernel_size, stride, pad))\n",
        "                if activation == 'leaky':\n",
        "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
        "                elif activation == 'relu':\n",
        "                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\n",
        "                prev_filters = filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'trans_conv':\n",
        "                conv_id = conv_id + 1\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                filters = int(block['filters'])\n",
        "                kernel_size = int(block['size'])\n",
        "                stride = int(block['stride'])\n",
        "                is_pad = int(block['pad'])\n",
        "                pad = (kernel_size - 1) // 2 if is_pad else 0\n",
        "                activation = block['activation']\n",
        "                model = nn.Sequential()\n",
        "                if batch_normalize:\n",
        "                    model.add_module('conv{0}'.format(conv_id),\n",
        "                                     nn.ConvTranspose2d(prev_filters, filters, kernel_size, stride,\n",
        "                                                        pad, output_padding=1, bias=False))\n",
        "                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\n",
        "                else:\n",
        "                    model.add_module('conv{0}'.format(conv_id),\n",
        "                                     nn.ConvTranspose2d(prev_filters, filters, kernel_size, stride, pad))\n",
        "                if activation == 'leaky':\n",
        "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
        "                elif activation == 'relu':\n",
        "                    model.add_module('relu{0}'.format(conv_id), nn.ReLU(inplace=True))\n",
        "                prev_filters = filters\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pool_size = int(block['size'])\n",
        "                stride = int(block['stride'])\n",
        "                if stride > 1:\n",
        "                    model = nn.MaxPool2d(pool_size, stride)\n",
        "                else:\n",
        "                    model = MaxPoolStride()\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(model)\n",
        "            elif block['type'] == 'route':\n",
        "                layers = block['layers'].split(',')\n",
        "                ind = len(models)\n",
        "                layers = [int(i) if int(i) > 0 else int(i) + ind for i in layers]\n",
        "                if len(layers) == 1:\n",
        "                    prev_filters = out_filters[layers[0]]\n",
        "                elif len(layers) == 2:\n",
        "                    assert (layers[0] == ind - 1)\n",
        "                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
        "                elif len(layers) == 3:\n",
        "                    assert (layers[0] == ind - 1)\n",
        "                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]] + out_filters[layers[2]]\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(EmpotyModule())\n",
        "            elif block['type'] == 'region':\n",
        "                loss = RegionLoss()\n",
        "                anchors = block['anchors'].split(',')\n",
        "                loss.anchors = [float(i) for i in anchors]\n",
        "                loss.num_classes = int(block['classes'])\n",
        "                loss.num_anchors = int(block['num'])\n",
        "                loss.anchor_step = len(loss.anchors) // loss.num_anchors\n",
        "                loss.object_scale = float(block['object_scale'])\n",
        "                loss.noobject_scale = float(block['noobject_scale'])\n",
        "                loss.class_scale = float(block['class_scale'])\n",
        "                loss.coord_scale = float(block['coord_scale'])\n",
        "                out_filters.append(prev_filters)\n",
        "                models.append(loss)\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "\n",
        "        return models\n",
        "\n",
        "    def load_weights(self, weightfile):\n",
        "        fp = open(weightfile, 'rb')\n",
        "        header = np.fromfile(fp, count=4, dtype=np.int32)\n",
        "        self.header = torch.from_numpy(header)\n",
        "        self.seen = self.header[3]\n",
        "        buf = np.fromfile(fp, dtype=np.float32)\n",
        "        fp.close()\n",
        "\n",
        "        start = 0\n",
        "        ind = -2\n",
        "        for block in self.blocks:\n",
        "            if start >= buf.size:\n",
        "                break\n",
        "            ind = ind + 1\n",
        "            # if ind == 24:\n",
        "            #     break\n",
        "            if block['type'] == 'net':\n",
        "                continue\n",
        "            elif block['type'] == 'iorn_convolutional':\n",
        "                model = self.models[ind]\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                if batch_normalize:\n",
        "                    start = load_conv_bn(buf, start, model[0], model[1])\n",
        "                else:\n",
        "                    start = load_conv(buf, start, model[0])\n",
        "            elif block['type'] == 'convolutional' or block['type'] == 'trans_conv':\n",
        "                model = self.models[ind]\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                if batch_normalize:\n",
        "                    start = load_conv_bn(buf, start, model[0], model[1])\n",
        "                else:\n",
        "                    start = load_conv(buf, start, model[0])\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pass\n",
        "            elif block['type'] == 'route':\n",
        "                pass\n",
        "            elif block['type'] == 'region':\n",
        "                pass\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "\n",
        "    def save_weights(self, outfile, cutoff=0):\n",
        "        if cutoff <= 0:\n",
        "            cutoff = len(self.blocks) - 1\n",
        "\n",
        "        fp = open(outfile, 'wb')\n",
        "        self.header[3] = self.seen\n",
        "        header = self.header\n",
        "        header.numpy().tofile(fp)\n",
        "        ind = -1\n",
        "        for blockId in range(1, cutoff + 1):\n",
        "            ind = ind + 1\n",
        "            block = self.blocks[blockId]\n",
        "            if block['type'] == 'iorn_convolutional':\n",
        "                model = self.models[ind]\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                if batch_normalize:\n",
        "                    save_conv_bn(fp, model[0], model[1])\n",
        "                else:\n",
        "                    save_conv(fp, model[0])\n",
        "            elif block['type'] == 'convolutional' or block['type'] == 'trans_conv':\n",
        "                model = self.models[ind]\n",
        "                batch_normalize = int(block['batch_normalize'])\n",
        "                if batch_normalize:\n",
        "                    save_conv_bn(fp, model[0], model[1])\n",
        "                else:\n",
        "                    save_conv(fp, model[0])\n",
        "            elif block['type'] == 'maxpool':\n",
        "                pass\n",
        "            elif block['type'] == 'route':\n",
        "                pass\n",
        "            elif block['type'] == 'region':\n",
        "                pass\n",
        "            else:\n",
        "                print('unknown type %s' % (block['type']))\n",
        "        fp.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcmmmOuEKTC_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZkpXy-IKTAG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a2Vh5lOKPyu"
      },
      "source": [
        "## image\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "####################################################\n",
        "import shapely.geometry as geometry\n",
        "##  //  import dota_process\n",
        "####################################################\n",
        "\n",
        "\n",
        "def distort_image(im, hue, sat, val):\n",
        "    im = im.convert('HSV')\n",
        "    cs = list(im.split())\n",
        "    cs[1] = cs[1].point(lambda i: i * sat)\n",
        "    cs[2] = cs[2].point(lambda i: i * val)\n",
        "    \n",
        "    def change_hue(x):\n",
        "        x += hue*255\n",
        "        if x > 255:\n",
        "            x -= 255\n",
        "        if x < 0:\n",
        "            x += 255\n",
        "        return x\n",
        "    cs[0] = cs[0].point(change_hue)\n",
        "    im = Image.merge(im.mode, tuple(cs))\n",
        "\n",
        "    im = im.convert('RGB')\n",
        "    return im\n",
        "\n",
        "\n",
        "def rand_scale(s):\n",
        "    scale = random.uniform(1, s)\n",
        "    if random.randint(1, 10000) % 2:\n",
        "        return scale\n",
        "    return 1./scale\n",
        "\n",
        "\n",
        "def random_distort_image(im, hue, saturation, exposure):\n",
        "    dhue = random.uniform(-hue, hue)\n",
        "    dsat = rand_scale(saturation)\n",
        "    dexp = rand_scale(exposure)\n",
        "    res = distort_image(im, dhue, dsat, dexp)\n",
        "    return res\n",
        "\n",
        "\n",
        "####################################################\n",
        "def data_augmentation(img, shape, jitter, hue, saturation, exposure):\n",
        "    oh = img.height\n",
        "    ow = img.width\n",
        "\n",
        "    dw = int(ow * jitter)\n",
        "    dh = int(oh * jitter)\n",
        "\n",
        "    pleft = random.randint(-dw, dw)\n",
        "    pright = random.randint(-dw, dw)\n",
        "    ptop = random.randint(-dh, dh)\n",
        "    pbot = random.randint(-dh, dh)\n",
        "\n",
        "    swidth = ow - pleft - pright\n",
        "    sheight = oh - ptop - pbot\n",
        "\n",
        "    flip = random.randint(1, 10000) % 2\n",
        "    cropped = img.crop((pleft, ptop, pleft + swidth - 1, ptop + sheight - 1))\n",
        "\n",
        "    sized = cropped.resize(shape)\n",
        "\n",
        "    if flip:\n",
        "        sized = sized.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    img = random_distort_image(sized, hue, saturation, exposure)\n",
        "\n",
        "    return img, flip, swidth, sheight, pleft, ptop\n",
        "####################################################\n",
        "\n",
        "\n",
        "def fill_truth_detection(labpath, w, h, flip, swidth, sheight, pleft, ptop):\n",
        "    max_boxes = 800\n",
        "    cc = 0\n",
        "    label = np.zeros((max_boxes, 5))\n",
        "\n",
        "    left = max(pleft, 0)\n",
        "    right = min((pleft + swidth), w)\n",
        "    up = max(ptop, 0)\n",
        "    down = min((ptop + sheight), h)\n",
        "\n",
        "    objects = dota_process.read_dota_gt(labpath)\n",
        "    if objects is None:\n",
        "        return label\n",
        "    imgbox = geometry.Polygon([(left, up), (right, up), (right, down),\n",
        "                               (left, down)])\n",
        "\n",
        "    for obj in objects:\n",
        "        gtbox = geometry.Polygon([(obj['box'][0], obj['box'][1]),\n",
        "                                  (obj['box'][2], obj['box'][3]),\n",
        "                                  (obj['box'][4], obj['box'][5]),\n",
        "                                  (obj['box'][6], obj['box'][7])])\n",
        "        if gtbox.area <= 0:\n",
        "            continue\n",
        "        inter_box, half_iou = dota_process.calc_half_iou(gtbox, imgbox)\n",
        "        if half_iou == 1:\n",
        "            boxInsub = dota_process.boxorig2sub(pleft, ptop, obj['box'])\n",
        "        elif half_iou > 0.3:\n",
        "            inter_box = geometry.polygon.orient(inter_box, sign=1)\n",
        "            out_box = list(inter_box.exterior.coords)[0: -1]\n",
        "            if len(out_box) < 4:\n",
        "                continue\n",
        "            out_box2 = []\n",
        "            for i in range(len(out_box)):\n",
        "                out_box2.append(out_box[i][0])\n",
        "                out_box2.append(out_box[i][1])\n",
        "\n",
        "            if len(out_box) == 5:\n",
        "                out_box2 = dota_process.box5_box4(out_box2)\n",
        "            elif len(out_box) > 5:\n",
        "                continue\n",
        "            out_box2 = dota_process.choose_best_point_order_fit_another(out_box2, obj['box'])\n",
        "            boxInsub = dota_process.boxorig2sub(left, up, out_box2)\n",
        "\n",
        "            for index, item in enumerate(boxInsub):\n",
        "                if index % 2 == 0:\n",
        "                    if item <= 1:\n",
        "                        boxInsub[index] = 1\n",
        "                    elif item >= swidth:\n",
        "                        boxInsub[index] = swidth\n",
        "                elif index % 2 == 1:\n",
        "                    if item <= 1:\n",
        "                        boxInsub[index] = 1\n",
        "                    elif item >= sheight:\n",
        "                        boxInsub[index] = sheight\n",
        "        else:\n",
        "            continue\n",
        "        length = max(np.abs(np.subtract(boxInsub[0], boxInsub[4])), np.abs(np.subtract(boxInsub[1], boxInsub[5])))\n",
        "        boxInsub = [(boxInsub[0], boxInsub[1]), (boxInsub[2], boxInsub[3]), (boxInsub[4], boxInsub[5]),\n",
        "                    (boxInsub[6], boxInsub[7])]\n",
        "\n",
        "        if (length / min(swidth, sheight)) < (5.0/704.0) and geometry.Polygon(boxInsub).area < 15:\n",
        "            continue\n",
        "        rect_minx = geometry.Polygon(boxInsub).bounds[0]\n",
        "        rect_miny = geometry.Polygon(boxInsub).bounds[1]\n",
        "        rect_maxx = geometry.Polygon(boxInsub).bounds[2]\n",
        "        rect_maxy = geometry.Polygon(boxInsub).bounds[3]\n",
        "        if max(abs(rect_maxx - rect_minx)/swidth, abs(rect_maxy - rect_miny)/sheight) < (5.0/704.0) \\\n",
        "                or min(abs(rect_maxx - rect_minx)/swidth, abs(rect_maxy - rect_miny)/sheight) <= 0:\n",
        "            continue\n",
        "        label[cc][0] = dota_process.classnames.index(obj['name'])\n",
        "        if flip:\n",
        "            label[cc][1] = 0.999 - abs(rect_maxx + rect_minx) / (2.0 * swidth)\n",
        "        else:\n",
        "            label[cc][1] = abs(rect_maxx + rect_minx) / (2.0 * swidth)\n",
        "        label[cc][2] = abs(rect_maxy + rect_miny) / (2.0 * sheight)\n",
        "        label[cc][3] = abs(rect_maxx - rect_minx) / swidth\n",
        "        label[cc][4] = abs(rect_maxy - rect_miny) / sheight\n",
        "        cc += 1\n",
        "        if cc >= 800:\n",
        "            break\n",
        "    label = np.reshape(label, (-1))\n",
        "    return label\n",
        "####################################################\n",
        "\n",
        "\n",
        "def load_data_detection(imgpath, shape, jitter, hue, saturation, exposure):\n",
        "    labpath = imgpath.replace('images', 'labels').replace('JPEGImages', 'labels').replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "\n",
        "    ## data augmentation\n",
        "    img = Image.open(imgpath).convert('RGB')\n",
        "    ####################################################\n",
        "    img, flip, swidth, sheight, pleft, ptop = data_augmentation(img, shape, jitter, hue, saturation, exposure)\n",
        "    label = fill_truth_detection(labpath, img.width, img.height, flip, swidth, sheight, pleft, ptop)\n",
        "    ####################################################\n",
        "    return img, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5u-YMAGKUaR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdBCwPsNKUXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow916WKYGItO"
      },
      "source": [
        "# dataset\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "##  //  from utils import read_truths_args\n",
        "##  //  from image import *\n",
        "\n",
        "\n",
        "class listDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root, shape=None, shuffle=True, transform=None, target_transform=None, train=False, seen=0, batch_size=64, num_workers=24):\n",
        "        with open(root, 'r') as file:\n",
        "            self.lines = file.readlines()\n",
        "\n",
        "        if shuffle:\n",
        "            random.shuffle(self.lines)\n",
        "\n",
        "        self.nSamples = len(self.lines)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.seen = seen\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error'\n",
        "        imgpath = self.lines[index].rstrip()\n",
        "\n",
        "        if self.train:\n",
        "            jitter = 0.2\n",
        "            hue = 0.1\n",
        "            saturation = 1.5 \n",
        "            exposure = 1.5\n",
        "\n",
        "            img, label = load_data_detection(imgpath, self.shape, jitter, hue, saturation, exposure)\n",
        "            label = torch.from_numpy(label)\n",
        "        else:\n",
        "            img = Image.open(imgpath).convert('RGB')\n",
        "            if self.shape:\n",
        "                img = img.resize(self.shape)\n",
        "    \n",
        "            labpath = imgpath.replace('images', 'labels').replace('JPEGImages', 'labels').replace('.jpg', '.txt').replace('.png','.txt')\n",
        "            label = torch.zeros(800*5)\n",
        "            try:\n",
        "                tmp = torch.from_numpy(read_truths_args(labpath, 5.0/img.width, self.shape).astype('float32'))\n",
        "            except Exception:\n",
        "                tmp = torch.zeros(1, 5)\n",
        "            tmp = tmp.view(-1)\n",
        "            tsz = tmp.numel()\n",
        "            if tsz > 800*5:\n",
        "                label = tmp[0:800*5]\n",
        "            elif tsz > 0:\n",
        "                label[0:tsz] = tmp\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        self.seen = self.seen + self.num_workers\n",
        "        return (img, label)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8tqDmUqKUUw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2MPmTipKURu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uqIF7psJuDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "532b3bf6-2715-4871-cfe7-ed8c4329b871"
      },
      "source": [
        "## test for map\n",
        "\n",
        "##  //  from utils import *\n",
        "##  //  from deform_darknet import deformDarknet, get_region_boxes\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "seed = int(time.time())\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def write_boxes(img, file_name, boxes, class_names=None, Result_dir=None):\n",
        "    file_class = []\n",
        "    for i in range(len(class_names)):\n",
        "        file_class.append(open(Result_dir + '/Task2_'+class_names[i]+'.txt', 'a'))\n",
        "\n",
        "    width = img.width\n",
        "    height = img.height\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        x1 = (box[0] - box[2]/2.0) * width\n",
        "        y1 = (box[1] - box[3]/2.0) * height\n",
        "        x2 = (box[0] + box[2]/2.0) * width\n",
        "        y2 = (box[1] + box[3]/2.0) * height\n",
        "\n",
        "        cls_id = box[6]\n",
        "        conf = box[4]*box[5]\n",
        "        file_class[cls_id].write(file_name.split('/')[-1].split('.')[0]+' '+str(conf)+' '+str(x1)+' '+str(y1)+' '+str(x2)+' '+str(y2)+'\\n')\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        file_class[i].close()\n",
        "\n",
        "\n",
        "def detect(model, weightfile, imgfile, Result_dir):\n",
        "\n",
        "    conf_thresh = 0.01\n",
        "    nms_thresh = 0.4\n",
        "    model.load_weights(weightfile)\n",
        "    print('Loading weights from %s... Done!' % (weightfile))\n",
        "    namesfile = 'data/dota.names'\n",
        "    model.eval()\n",
        "    use_cuda = 1\n",
        "    if use_cuda:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        model.cuda()\n",
        "#################################################################\n",
        "    img_list_file = open(imgfile)\n",
        "    img_list = img_list_file.readlines()\n",
        "    img_list_file.close()\n",
        "    # img_list = os.listdir(imgfile)\n",
        "#################################################################\n",
        "    for imgpath in img_list:\n",
        "        imgpath = imgpath.strip('\\n')\n",
        "        img = Image.open(imgpath).convert('RGB')\n",
        "        x_idx = range(0, img.width, 1024-512)\n",
        "        y_idx = range(0, img.height, 1024-512)\n",
        "        all_boxes = []\n",
        "        for x_start in x_idx:\n",
        "            for y_start in y_idx:\n",
        "                x_stop = x_start + 1024\n",
        "                if x_stop > img.width:\n",
        "                    x_start = img.width - 1024\n",
        "                    x_stop = img.width\n",
        "                y_stop = y_start + 1024\n",
        "                if y_stop > img.height:\n",
        "                    y_start = img.height - 1024\n",
        "                    y_stop = img.height\n",
        "                croped_img = img.crop((x_start, y_start, x_stop, y_stop))\n",
        "                croped_img = transforms.ToTensor()(croped_img)\n",
        "                croped_img = torch.unsqueeze(croped_img, 0)\n",
        "                croped_img = Variable(croped_img, requires_grad=False)\n",
        "                output = model(croped_img.cuda()).data\n",
        "                boxes = get_region_boxes(output, conf_thresh, model.num_classes, model.anchors, model.num_anchors,\n",
        "                                         x_start, y_start, img.width, img.height, validation=True)[0]\n",
        "                all_boxes = all_boxes + boxes\n",
        "        boxes = nms(all_boxes, nms_thresh)\n",
        "        class_names = load_class_names(namesfile)\n",
        "        # write_boxes(imgpath, boxes, Result_dir)\n",
        "        write_boxes(img, imgpath, boxes, class_names, Result_dir)\n",
        "        print(\"save results of %s\" % imgpath)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    workdir = '/content/drive/My Drive/DOTA-dataset/'\n",
        "    cfgfile = workdir + 'cfg/orn_4_dota.cfg'\n",
        "    model = deformDarknet(cfgfile)\n",
        "    imgfile = '/home/lwc/my_prj/DOTA/val/val/images/val_list.txt'\n",
        "\n",
        "    weightfile_list = open(workdir + 'backup/weight_list.txt').readlines()\n",
        "\n",
        "    num_weight = weightfile_list.__len__()\n",
        "    for idx_weight in range(num_weight):\n",
        "        weightfile = workdir + 'backup/' + weightfile_list[idx_weight].strip('\\n')\n",
        "        Result_dir = workdir + 'backup/' + weightfile_list[idx_weight].split('.')[0]\n",
        "        if not os.path.exists(Result_dir):\n",
        "            os.mkdir(Result_dir)\n",
        "        detect(model, weightfile, imgfile, Result_dir)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a1b1e2ac4030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mworkdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mcfgfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'cfg/orn_4_dota.cfg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeformDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mimgfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/lwc/my_prj/DOTA/val/val/images/val_list.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-7501fdc2e108>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfgfile)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeformDarknet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-dd6f522c7eda>\u001b[0m in \u001b[0;36mparse_cfg\u001b[0;34m(cfgfile)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cfg/orn_4_dota.cfg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hiGB6DnKW9D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k94-x5TlKvlR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "dzVPbVaPeE-a",
        "outputId": "67fcad45-0fc5-4213-e691-c7fef5de3ca2"
      },
      "source": [
        "## train\n",
        "\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "if len(sys.argv) != 4:\n",
        "    print('Usage:')\n",
        "    print('python train.py datacfg cfgfile weightfile')\n",
        "    exit()\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "##  //  import dataset\n",
        "##  //  from utils import *\n",
        "##  //  from config import parse_cfg\n",
        "##  //  from deform_darknet import deformDarknet, get_region_boxes\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Training settings\n",
        "datacfg       = sys.argv[1]\n",
        "cfgfile       = sys.argv[2]\n",
        "weightfile    = sys.argv[3]\n",
        "\n",
        "data_options  = read_data_cfg(datacfg)\n",
        "net_options   = parse_cfg(cfgfile)[0]\n",
        "\n",
        "trainlist     = data_options['train']\n",
        "testlist      = data_options['valid']\n",
        "backupdir     = data_options['backup']\n",
        "nsamples      = file_lines(trainlist)\n",
        "gpus          = data_options['gpus']\n",
        "ngpus         = len(gpus.split(','))\n",
        "num_workers   = int(data_options['num_workers'])\n",
        "\n",
        "batch_size    = int(net_options['batch'])\n",
        "subdiv        = int(net_options['subdivisions'])\n",
        "max_batches   = int(net_options['max_batches'])\n",
        "learning_rate = float(net_options['learning_rate'])\n",
        "momentum      = float(net_options['momentum'])\n",
        "decay         = float(net_options['decay'])\n",
        "steps         = [float(step) for step in net_options['steps'].split(',')]\n",
        "scales        = [float(scale) for scale in net_options['scales'].split(',')]\n",
        "\n",
        "#Train parameters\n",
        "max_epochs    = max_batches*batch_size//nsamples+1\n",
        "use_cuda      = True\n",
        "seed          = int(time.time())\n",
        "eps           = 1e-5\n",
        "save_interval = 1   # epoches\n",
        "dot_interval  = 70  # batches\n",
        "\n",
        "# Test parameters\n",
        "conf_thresh   = 0.3\n",
        "nms_thresh    = 0.4\n",
        "iou_thresh    = 0.5\n",
        "############################################################\n",
        "if not os.path.exists(backupdir):\n",
        "    os.mkdir(backupdir)\n",
        "############################################################\n",
        "torch.manual_seed(seed)\n",
        "if use_cuda:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
        "    torch.cuda.manual_seed(seed)\n",
        "############################################################\n",
        "model = deformDarknet(cfgfile)\n",
        "############################################################\n",
        "init_epoch = int(weightfile.split('/')[-1].split('.')[0])\n",
        "############################################################\n",
        "model.load_weights(weightfile)\n",
        "#################################s###########################\n",
        "region_loss = model.loss\n",
        "region_loss.seen = model.seen\n",
        "processed_batches = model.seen//batch_size\n",
        "\n",
        "init_width = model.width\n",
        "init_height = model.height\n",
        "############################################################\n",
        "kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset.listDataset(testlist, shape=(init_width, init_height),\n",
        "                   shuffle=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]), train=False),\n",
        "    batch_size=batch_size//subdiv, shuffle=False, **kwargs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset.listDataset(trainlist, shape=(init_width, init_height),\n",
        "                        shuffle=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                        ]),\n",
        "                        train=True,\n",
        "                        seen=model.seen,\n",
        "                        batch_size=batch_size // subdiv,\n",
        "                        num_workers=num_workers // subdiv),\n",
        "    batch_size=batch_size // subdiv, shuffle=False, **kwargs)\n",
        "############################################################\n",
        "if use_cuda:\n",
        "    if ngpus > 1:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "    else:\n",
        "        model = model.cuda()\n",
        "############################################################\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate/batch_size, weight_decay=decay*batch_size)\n",
        "# optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=learning_rate/batch_size, weight_decay=decay*batch_size)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    global processed_batches\n",
        "    if ngpus > 1:\n",
        "        cur_model = model.module\n",
        "    else:\n",
        "        cur_model = model\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        processed_batches = processed_batches + 1\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        region_loss.seen = region_loss.seen + data.data.size(0)\n",
        "        loss = region_loss(output, target, batch_idx)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % save_interval == 0:\n",
        "        logging('save weights to %s/%06d.weights' % (backupdir, epoch+1))\n",
        "        cur_model.seen = (epoch + 1) * len(train_loader.dataset)\n",
        "        cur_model.save_weights('%s/%06d.weights' % (backupdir, epoch + 1))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    if ngpus > 1:\n",
        "        cur_model = model.module\n",
        "    else:\n",
        "        cur_model = model\n",
        "    num_classes = cur_model.num_classes\n",
        "    anchors = cur_model.anchors\n",
        "    num_anchors = cur_model.num_anchors\n",
        "    total = 0.0\n",
        "    proposals = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        data = Variable(data, requires_grad=False)\n",
        "        output = model(data).data\n",
        "        all_boxes = get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors)\n",
        "        for i in range(output.size(0)):\n",
        "            boxes = all_boxes[i]\n",
        "            boxes = nms(boxes, nms_thresh)\n",
        "            truths = target[i].view(-1, 5)\n",
        "            num_gts = truths_length(truths)\n",
        "            total = total + num_gts\n",
        "            for j in range(len(boxes)):\n",
        "                if boxes[j][4] > conf_thresh:\n",
        "                    proposals = proposals + 1\n",
        "            for k in range(num_gts):\n",
        "                box_gt = [truths[k][1], truths[k][2], truths[k][3], truths[k][4], 1.0, 1.0, truths[k][0]]\n",
        "                best_iou = 0\n",
        "                best_j = 0\n",
        "                for j in range(len(boxes)):\n",
        "                    iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_j = j\n",
        "                if best_iou > iou_thresh and boxes[best_j][4] > conf_thresh and boxes[best_j][6] == box_gt[6]:\n",
        "                    correct = correct + 1\n",
        "\n",
        "    precision = 1.0 * correct / (proposals + eps)\n",
        "    recall = 1.0 * correct / (total + eps)\n",
        "    fscore = 2.0 * precision * recall / (precision + recall + eps)\n",
        "    logging(\"precision: %f, recall: %f, fscore: %f\" % (precision, recall, fscore))\n",
        "    fp = open('./log.dat', 'a')\n",
        "    fp.write(\"precision: %f, recall: %f, fscore: %f\\n\" % (precision, recall, fscore))\n",
        "    fp.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for epoch in range(init_epoch, max_epochs):\n",
        "        train(epoch)\n",
        "        if epoch % 4 == 3:\n",
        "            test()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage:\n",
            "python train.py datacfg cfgfile weightfile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-de8888f8d3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdatacfg\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcfgfile\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mweightfile\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata_options\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mread_data_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatacfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxaWJAu3GHIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOVXSN3mGEjm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7wMZ4X9JuL-"
      },
      "source": [
        "## detect\n",
        "\n",
        "##  //  from utils import *\n",
        "##  //  from deform_darknet import deformDarknet, get_region_boxes\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "seed = int(time.time())\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def detect(model, weightfile, imgfile, Result_dir):\n",
        "\n",
        "    conf_thresh = 0.5\n",
        "    nms_thresh = 0.4\n",
        "    model.load_weights(weightfile)\n",
        "    print('Loading weights from %s... Done!' % (weightfile))\n",
        "    namesfile = 'data/dota.names'\n",
        "    model.eval()\n",
        "    use_cuda = 1\n",
        "    if use_cuda:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        model.cuda()\n",
        "#################################################################\n",
        "    img_list_file = open(imgfile)\n",
        "    img_list = img_list_file.readlines()\n",
        "    img_list_file.close()\n",
        "#################################################################\n",
        "    for imgpath in img_list:\n",
        "        imgpath = imgpath.strip('\\n')\n",
        "        img = Image.open(imgpath).convert('RGB')\n",
        "        x_idx = range(0, img.width, 1024-512)\n",
        "        y_idx = range(0, img.height, 1024-512)\n",
        "        all_boxes = []\n",
        "        for x_start in x_idx:\n",
        "            for y_start in y_idx:\n",
        "                x_stop = x_start + 1024\n",
        "                if x_stop > img.width:\n",
        "                    x_start = img.width - 1024\n",
        "                    x_stop = img.width\n",
        "                y_stop = y_start + 1024\n",
        "                if y_stop > img.height:\n",
        "                    y_start = img.height - 1024\n",
        "                    y_stop = img.height\n",
        "                croped_img = img.crop((x_start, y_start, x_stop, y_stop))\n",
        "                croped_img = transforms.ToTensor()(croped_img)\n",
        "                croped_img = torch.unsqueeze(croped_img, 0)\n",
        "                croped_img = Variable(croped_img, requires_grad=False)\n",
        "                output = model(croped_img.cuda()).data\n",
        "                boxes = get_region_boxes(output, conf_thresh, model.num_classes, model.anchors, model.num_anchors,\n",
        "                                         x_start, y_start, img.width, img.height, validation=True)[0]\n",
        "                all_boxes = all_boxes + boxes\n",
        "        boxes = nms(all_boxes, nms_thresh)\n",
        "\n",
        "        class_names = load_class_names(namesfile)\n",
        "        plot_boxes(img, boxes, os.path.join(Result_dir, imgpath.split('/')[-1]), class_names)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    workdir = '/content/drive/My Drive/DOTA-dataset/'\n",
        "    cfgfile = workdir + 'cfg/orn_4_dota.cfg'\n",
        "    model = deformDarknet(cfgfile)\n",
        "    imgfile = '/content/drive/My Drive/DOTA-dataset/test_img/test_img_list.txt'\n",
        "\n",
        "    weightfile_list = open(workdir + 'backup/test_weight_list.txt').readlines()\n",
        "\n",
        "    num_weight = weightfile_list.__len__()\n",
        "    for idx_weight in range(num_weight):\n",
        "        weightfile = workdir + 'backup/' + weightfile_list[idx_weight].strip('\\n')\n",
        "        Result_dir = workdir + 'final_result/test_img/'\n",
        "        if not os.path.exists(Result_dir):\n",
        "            os.mkdir(Result_dir)\n",
        "        detect(model, weightfile, imgfile, Result_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9NA-hY3GEg1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiT5C6F5GEeX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdM8k-pjGEW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB-9RNx1GEUP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaVcJzrJGERh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxM3-GQWGENf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Nm9_qwGEC_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}